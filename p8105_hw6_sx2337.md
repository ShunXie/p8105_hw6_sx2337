p8105_hw6_sx2337
================
Shun Xie
2022-11-20

``` r
suppressMessages(library(tidyverse))
suppressMessages(library(dbplyr))
options(tibble.print_min = 5)
```

# Problem 1

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: C:\Users\ALIENW~1\AppData\Local/Cache/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2022-11-20 10:40:09 (8.443)

    ## file min/max dates: 1869-01-01 / 2022-11-30

for $r^2$

``` r
results_df = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results_r = map(models, broom::glance),
    results_beta = map(models, broom::tidy)) 
```

``` r
r_val_info = 
  results_df %>% 
  select(results_r) %>% 
  unnest()
```

    ## Warning: `cols` is now required when using unnest().
    ## Please use `cols = c(results_r)`

``` r
r_val_info %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

![](p8105_hw6_sx2337_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

``` r
r_val_info %>% 
  summarize(
    mean_Val = mean(r.squared),
    median_val = median(r.squared),
    se = sd(r.squared),
    "2.5-quantile" = mean(r.squared)+qnorm(0.025)*sd(r.squared),
    "97.5-quantile" = mean(r.squared)+qnorm(0.775)*sd(r.squared)
  )
```

    ## # A tibble: 1 × 5
    ##   mean_Val median_val      se `2.5-quantile` `97.5-quantile`
    ##      <dbl>      <dbl>   <dbl>          <dbl>           <dbl>
    ## 1    0.911      0.912 0.00864          0.894           0.918

R square is likely to be symmetrically distributed with mean 0.91 and
median 0.91.

The 2.5% quantile and 97.5% quantile is therefore: 0.894 to 0.918.

For log_value of beta_0 and beta_1:

``` r
logbeta_val_info = 
  results_df %>% 
  select(results_beta) %>% 
  unnest(results_beta) %>% 
  select(term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  unnest() %>% 
  mutate(logval = log(intercept+tmin))

logbeta_val_info %>% 
  ggplot(aes(x = logval)) + geom_density()
```

![](p8105_hw6_sx2337_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

``` r
logbeta_val_info %>% 
  summarize(
    mean_Val = mean(logval),
    median_val = median(logval),
    se = sd(logval),
    "2.5-quantile" = mean(logval)+qnorm(0.025)*sd(logval),
    "97.5-quantile" = mean(logval)+qnorm(0.775)*sd(logval)
  )
```

    ## # A tibble: 1 × 5
    ##   mean_Val median_val     se `2.5-quantile` `97.5-quantile`
    ##      <dbl>      <dbl>  <dbl>          <dbl>           <dbl>
    ## 1     2.11       2.11 0.0294           2.05            2.13

log value of $log(\beta_0+\beta_1)$ is likely to be symmetrically
distributed with mean 2.11 and median 2.11.

The 2.5% quantile and 97.5% quantile is therefore: 2.053 to 2.132.

# Problem 2

In this question, will explore the homocides data in 50 large US cities.

``` r
homocide_data = read_csv("data/homicide-data.csv", show_col_types = FALSE) %>% 
  replace(is.na(.),0)
homocide_data
```

    ## # A tibble: 52,179 × 12
    ##   uid    repor…¹ victi…² victi…³ victi…⁴ victi…⁵ victi…⁶ city  state   lat   lon
    ##   <chr>    <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr> <chr> <dbl> <dbl>
    ## 1 Alb-0…  2.01e7 GARCIA  JUAN    Hispan… 78      Male    Albu… NM     35.1 -107.
    ## 2 Alb-0…  2.01e7 MONTOYA CAMERON Hispan… 17      Male    Albu… NM     35.1 -107.
    ## 3 Alb-0…  2.01e7 SATTER… VIVIANA White   15      Female  Albu… NM     35.1 -107.
    ## 4 Alb-0…  2.01e7 MENDIO… CARLOS  Hispan… 32      Male    Albu… NM     35.1 -107.
    ## 5 Alb-0…  2.01e7 MULA    VIVIAN  White   72      Female  Albu… NM     35.1 -107.
    ## # … with 52,174 more rows, 1 more variable: disposition <chr>, and abbreviated
    ## #   variable names ¹​reported_date, ²​victim_last, ³​victim_first, ⁴​victim_race,
    ## #   ⁵​victim_age, ⁶​victim_sex

Then, create a city_state variable to combine city and state together,
as well as a binary variable indicating solved and non-solved case. Also
omit cities as required in the question. Additionally, only consider
victim_race as white or black so only include white and black race. Note
that there is some cases where victim_age is unknown and victim_sex has
unknown values, discard them

``` r
homocide_data_new = 
  homocide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>% 
  mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state=="Dallas, TX", !city_state=="Phoenix, AZ", !city_state=="Kansas City, MO", !city_state=="Tulsa, AL") %>% 
  filter(victim_race=="White" | victim_race=="Black") %>% 
  mutate(victim_race = fct_relevel(victim_race, "White")) %>% 
  filter(!victim_age=="Unknown",
         !victim_sex=="Unknown") %>% 
  mutate(victim_age = as.numeric(victim_age),
         victim_sex = ifelse(victim_sex=="Male",1,0))
         

homocide_data_new 
```

    ## # A tibble: 39,362 × 14
    ##   uid    repor…¹ victi…² victi…³ victi…⁴ victi…⁵ victi…⁶ city  state   lat   lon
    ##   <chr>    <dbl> <chr>   <chr>   <fct>     <dbl>   <dbl> <chr> <chr> <dbl> <dbl>
    ## 1 Alb-0…  2.01e7 SATTER… VIVIANA White        15       0 Albu… NM     35.1 -107.
    ## 2 Alb-0…  2.01e7 MULA    VIVIAN  White        72       0 Albu… NM     35.1 -107.
    ## 3 Alb-0…  2.01e7 BOOK    GERALD… White        91       0 Albu… NM     35.2 -107.
    ## 4 Alb-0…  2.01e7 MARTIN… GUSTAVO White        56       1 Albu… NM     35.1 -107.
    ## 5 Alb-0…  2.01e7 GRAY    STEFAN… White        43       0 Albu… NM     35.1 -107.
    ## # … with 39,357 more rows, 3 more variables: disposition <chr>,
    ## #   city_state <chr>, resolved <dbl>, and abbreviated variable names
    ## #   ¹​reported_date, ²​victim_last, ³​victim_first, ⁴​victim_race, ⁵​victim_age,
    ## #   ⁶​victim_sex

Now as required, use the glm function to fit a logistic regression with
resolved vs unresolved as the outcome and victim age, sex and race as
predictors for the city of Baltimore, MD.

``` r
# save the glm as r object
Baltimore_model= 
  homocide_data_new %>% 
  filter(city_state=="Baltimore, MD") %>% 
  glm(resolved ~ victim_age+victim_race+victim_sex, data=., family= binomial(link = "logit")) 
```

Based on the model, can obtain the log odds ratio estimate and
confidence interval. After that, transfer to odds ratio by taking
exponential of all values calculated.

``` r
Baltimore_model %>% 
  broom::tidy() %>% 
  mutate(lower_conf = confint(Baltimore_model)[,1],
         upper_conf = confint(Baltimore_model)[,2]) %>% 
  filter(term=='victim_sex') %>% 
  select(estimate, lower_conf, upper_conf) %>% 
  mutate(estimate = exp(estimate),
         lower_conf = exp(lower_conf),
         upper_conf = exp(upper_conf))
```

    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...

    ## # A tibble: 1 × 3
    ##   estimate lower_conf upper_conf
    ##      <dbl>      <dbl>      <dbl>
    ## 1    0.426      0.324      0.558

Therefore, in comparison to the baseline which is female, male has 0.425
times higher odds chance of getting a resolved case. Meaning that male
has a lower chance to have a solved case than female.

Repeat the process to all cities:

``` r
distinct_cities_df = 
  homocide_data_new %>% 
  select(city_state, victim_race:victim_sex, resolved) %>% 
  nest(sample = victim_race:resolved) %>% 
  mutate(
    models = map(sample, ~glm(resolved ~ victim_age+victim_race+victim_sex, family= binomial(link = "logit"), data=.x)),
    results = map(models, broom::tidy),
    conf_int = map(models, ~confint(.x,"victim_sex"))
  ) %>% 
  select(city_state,results,conf_int) %>% 
  unnest(results) %>% 
  unnest_wider(conf_int) %>% 
  filter(term=="victim_sex") %>% 
  select(city_state,estimate,`2.5 %`,`97.5 %`) %>% 
  #convert to odds scale
  mutate(
    estimate=exp(estimate),
    `2.5 %` =exp(`2.5 %`),
    `97.5 %` = exp(`97.5 %`)
    )
```

    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...

``` r
distinct_cities_df
```

    ## # A tibble: 47 × 4
    ##   city_state      estimate `2.5 %` `97.5 %`
    ##   <chr>              <dbl>   <dbl>    <dbl>
    ## 1 Albuquerque, NM    1.77    0.825    3.76 
    ## 2 Atlanta, GA        1.00    0.680    1.46 
    ## 3 Baltimore, MD      0.426   0.324    0.558
    ## 4 Baton Rouge, LA    0.381   0.204    0.684
    ## 5 Birmingham, AL     0.870   0.571    1.31 
    ## # … with 42 more rows

Now create a plot as following:

``` r
ggplot(distinct_cities_df, aes(x=fct_reorder(city_state, estimate), y=estimate))+
  geom_point()+
  geom_errorbar(aes(ymin=`2.5 %`, ymax=`97.5 %`))+
  labs(title = "Number of unsolved homocide among cities", )+xlab("City")+
  theme(axis.text.x = element_text(angle = 80, hjust = 1))
```

![](p8105_hw6_sx2337_files/figure-gfm/unnamed-chunk-13-1.png)<!-- -->
Can be ssen on the plot, most of the cities have an estimate less than
one, meaning that male are less likely to have a solved case than
female, which is set to be the base line of the logistic regression.
Some cities like New York, Baton Rouge, Chicago etc have an interval
that does not intercept 1, meaning that these cities have a significant
difference for solving cases between gender. It is likely that female
has a greater chance to have a homocide case solved than male. On ther
other hand, the city of Albuquerque, NM have a much higher estimate for
male to have a case solved. But the confidence interval overlap the
value of one, so we do not have enough evidence to prove that male and
female have significantly difference in number of unsolved case.

# Problem 3
