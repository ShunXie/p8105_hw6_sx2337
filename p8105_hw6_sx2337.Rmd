---
title: "p8105_hw6_sx2337"
author: "Shun Xie"
date: "2022-11-20"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, warning=FALSE}
suppressMessages(library(tidyverse))
suppressMessages(library(modelr))

suppressMessages(library(dbplyr))
options(tibble.print_min = 5)

```


# Problem 1

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```

for $r^2$
```{r}
results_df = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results_r = map(models, broom::glance),
    results_beta = map(models, broom::tidy)) 
```

```{r}
r_val_info = 
  results_df %>% 
  select(results_r) %>% 
  unnest()

r_val_info %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```
```{r}
r_val_info %>% 
  summarize(
    mean_Val = mean(r.squared),
    median_val = median(r.squared),
    se = sd(r.squared),
    "2.5-quantile" = mean(r.squared)+qnorm(0.025)*sd(r.squared),
    "97.5-quantile" = mean(r.squared)+qnorm(0.775)*sd(r.squared)
  )
```

R square is likely to be symmetrically distributed with mean 0.91 and median 0.91. 

The 2.5% quantile and 97.5% quantile is therefore:
0.894 to 0.918.

For log_value of beta_0 and beta_1:
```{r, warning=FALSE}
logbeta_val_info = 
  results_df %>% 
  select(results_beta) %>% 
  unnest(results_beta) %>% 
  select(term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  unnest() %>% 
  mutate(logval = log(intercept+tmin))

logbeta_val_info %>% 
  ggplot(aes(x = logval)) + geom_density()
```
```{r}
logbeta_val_info %>% 
  summarize(
    mean_Val = mean(logval),
    median_val = median(logval),
    se = sd(logval),
    "2.5-quantile" = mean(logval)+qnorm(0.025)*sd(logval),
    "97.5-quantile" = mean(logval)+qnorm(0.775)*sd(logval)
  )
```

log value of $log(\beta_0+\beta_1)$ is likely to be symmetrically distributed with mean 2.11 and median 2.11. 

The 2.5% quantile and 97.5% quantile is therefore:
2.053 to 2.132.


# Problem 2

In this question, will explore the homocides data in 50 large US cities. 
```{r}
homocide_data = read_csv("data/homicide-data.csv", show_col_types = FALSE) %>% 
  replace(is.na(.),0)
homocide_data
```

Then, create a city_state variable to combine city and state together, as well as a binary variable indicating solved and non-solved case. Also omit cities as required in the question. Additionally, only consider victim_race as white or black so only include white and black race. Note that there is some cases where victim_age is unknown and victim_sex has unknown values, discard them

```{r}
homocide_data_new = 
  homocide_data %>%
  mutate(city_state = str_c(city, ", ", state)) %>% 
  mutate(resolved = as.numeric(disposition == "Closed by arrest")) %>% 
  filter(!city_state=="Dallas, TX", !city_state=="Phoenix, AZ", !city_state=="Kansas City, MO", !city_state=="Tulsa, AL") %>% 
  filter(victim_race=="White" | victim_race=="Black") %>% 
  mutate(victim_race = fct_relevel(victim_race, "White")) %>% 
  filter(!victim_age=="Unknown",
         !victim_sex=="Unknown") %>% 
  mutate(victim_age = as.numeric(victim_age),
         victim_sex = ifelse(victim_sex=="Male",1,0))
         

homocide_data_new 
```


Now as required, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as predictors for the city of Baltimore, MD. 


```{r,warning=FALSE}
# save the glm as r object
Baltimore_model= 
  homocide_data_new %>% 
  filter(city_state=="Baltimore, MD") %>% 
  glm(resolved ~ victim_age+victim_race+victim_sex, data=., family= binomial(link = "logit")) 


#save as an R object
save(Baltimore_model, file = "results/Baltimore_model.RData")


```


Based on the model, can obtain the log odds ratio estimate and confidence interval. After that, transfer to odds ratio by taking exponential of all values calculated. 
```{r}
Baltimore_model %>% 
  broom::tidy() %>% 
  mutate(lower_conf = confint(Baltimore_model)[,1],
         upper_conf = confint(Baltimore_model)[,2]) %>% 
  filter(term=='victim_sex') %>% 
  select(estimate, lower_conf, upper_conf) %>% 
  mutate(estimate = exp(estimate),
         lower_conf = exp(lower_conf),
         upper_conf = exp(upper_conf))
  
```
Therefore, in comparison to the baseline which is female, male has 0.425 times higher odds chance of getting a resolved case. Meaning that male has a lower chance to have a solved case than female. 

Repeat the process to all cities:

```{r,message=FALSE}


distinct_cities_df = 
  homocide_data_new %>% 
  select(city_state, victim_race:victim_sex, resolved) %>% 
  nest(sample = victim_race:resolved) %>% 
  mutate(
    models = map(sample, ~glm(resolved ~ victim_age+victim_race+victim_sex, family= binomial(link = "logit"), data=.x)),
    results = map(models, broom::tidy),
    conf_int = map(models, ~confint(.x,"victim_sex"))
  ) %>% 
  select(city_state,results,conf_int) %>% 
  unnest(results) %>% 
  unnest_wider(conf_int) %>% 
  filter(term=="victim_sex") %>% 
  select(city_state,estimate,`2.5 %`,`97.5 %`) %>% 
  #convert to odds scale
  mutate(
    estimate=exp(estimate),
    `2.5 %` =exp(`2.5 %`),
    `97.5 %` = exp(`97.5 %`)
    )
  

distinct_cities_df
```

Now create a plot as following:
```{r}
ggplot(distinct_cities_df, aes(x=fct_reorder(city_state, estimate), y=estimate))+
  geom_point()+
  geom_errorbar(aes(ymin=`2.5 %`, ymax=`97.5 %`))+
  labs(title = "Number of unsolved homocide among cities", )+xlab("City")+
  theme(axis.text.x = element_text(angle = 80, hjust = 1))
```

Can be ssen on the plot, most of the cities have an estimate less than one, meaning that male are less likely to have a solved case than female, which is set to be the base line of the logistic regression. Some cities like New York, Baton Rouge, Chicago etc have an interval that does not intercept 1, meaning that these cities have a significant difference for solving cases between gender. It is likely that female has a greater chance to have a homocide case solved than male. On ther other hand, the city of Albuquerque, NM have a much higher estimate for male to have a case solved. But the confidence interval overlap the value of one, so we do not have enough evidence to prove that male and female have significantly difference in number of unsolved case.


# Problem 3

First, load and have a look at the data. 
```{r}
birthweight = read_csv("data/birthweight.csv", show_col_types = FALSE)
birthweight
sum(is.na(birthweight))
```
The data has 4342 samples with 20 variables. The frace, mrace are in numeric value. Thus, need to change them into factors. Additionally, gender may also be changed to factors There is no missing value but there are some values that has unknown value. Thus, need to discard the unknown value. The other values are in numerical form. 


```{r}
birthweight_adpt = 
  birthweight %>% 
  mutate(
    frace = recode(frace, `1` = "White", `2` = "Black", `3` = "Asian", `4` = "Puerto Rican", `8` = "Other", `9` = "Unknown"),
    mrace = recode(mrace, `1` = "White", `2` = "Black", `3` = "Asian", `4` = "Puerto Rican", `8` = "Other"),
    babysex = recode(babysex, `1` = "Male", `2` = "Female")
    )%>% 
    filter(frace!="Unknown") %>%
  mutate(
    frace = fct_relevel(frace, "White"),
    mrace = fct_relevel(mrace, "White"),
    babysex = fct_relevel(babysex,"Female")
         )
birthweight_adpt
```

First assume that all factors are related to baby's weight. For instance, a female baby may likely to have different weight than male baby due to different biological structure. Also other factors such as family income may also be related to baby's weight because a affluent family may have a better diet and therefore baby may have more nutrition than those family in poverty. Therefore, I choose all the factors to start with, and using backward selection to select the model.

```{r}
# Fit the full model 
Full_model <- lm(bwt ~., data = birthweight_adpt)
# begin stepwise procedure
Stepwise_model <- MASS::stepAIC(Full_model, direction = "backward", trace = FALSE)
summary(Stepwise_model)
```

Based on the model selected, I plot the residuals against fitted values:

```{r}
birthweight_adpt %>% 
  add_predictions(Stepwise_model) %>% 
  add_residuals(Stepwise_model) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point() + 
  geom_smooth()+
  labs(title = "Residuals against fitted values plot", )+xlab("fitted value")+ylab("residuals")

```

The plot shows that residuals clustered in one place and it seems like the variance is different along the fitted values. On the other hand, the model has a relatively high r square hence the model has a relatively high explained variance. 

Now fit the other two models as well as the chosen stepwise model using cross validation.

```{r, warning=FALSE}
#first create a dataframe 
cv_df =
  crossv_mc(birthweight_adpt, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

#then fit three models:
cv_df = 
  cv_df %>% 
  mutate(
    my_model  = map(train, ~lm( bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    main_effect_model  = map(train, ~lm(bwt ~ gaweeks + blength, data = .x)),
    interactive_model  = map(train, ~lm(bwt ~ bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
    rmse_main_effect    = map2_dbl(main_effect_model, test, ~rmse(model = .x, data = .y)),
    rmse_interactive = map2_dbl(interactive_model, test, ~rmse(model = .x, data = .y)))

#Get the summarize the result:
cv_df %>% 
  summarize(
    rmse_my_model_mean = mean(rmse_my_model),
    rmse_main_effect_mean = mean(rmse_main_effect),
    rmse_interactive_meam = mean(rmse_interactive)
  )
```

As indicated by the RMSE results, my model has the lowest rmse, with a decent adjusted r square value (which also considered the complexity of the model). Therefore, I choose my model with baby's sex, baby head circumference, baby's length at birth, mother weight at delivery, family monthly income,
    gestational age in weeks, mother's height, mother race, number of live births prior to this pregnancy, mother's pre-pregnancy BMI and mother's weight gain during pregnancy as predictors. 

